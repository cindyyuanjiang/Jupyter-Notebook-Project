{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning Algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope: [0.39390555]\n",
      "intercept; -0.031804343026759746\n",
      "\n",
      "Test Score: 0.65933685968637\n",
      "Train Score: 0.6700890315075756\n"
     ]
    }
   ],
   "source": [
    "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "slope = model.fit(X_train, y_train).coef_\n",
    "intercept = model.fit(X_train, y_train).intercept_\n",
    "\n",
    "print(\"slope: {}\\nintercept; {}\".format(slope, intercept))\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(\"\\nTest Score: {}\".format(test_score))\n",
    "print(\"Train Score: {}\".format(train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Ordinary linear model: mostly have higher train scores but don't generalize accurately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9520519609032729\n",
      "Test Score: 0.607472195966596\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Train Score: {}\\nTest Score: {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Ridge regression models:  \n",
    "have lower train scores they are used instead of linear models because they generalize better by avoiding overfitting using L2 Regularization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8857966585170941\n",
      "Test Score: 0.7527683481744756\n"
     ]
    }
   ],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Train Score: {}\\nTest Score: {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Lasso models: \n",
    "   ##### i. they use L1 regularization (means some coefficients are near zero)\n",
    "   ##### ii. some features are completely ignored \n",
    "   ##### iii. Using lower values for alpha and max_iter further improves our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-1 train Score: 0.2932376899111462\n",
      "Model-1 test Score: 0.20937503255272294\n",
      "Model-1 features used: 4\n",
      "\n",
      "Model-2 train Score: 0.915961898733442\n",
      "Model-2 test Score: 0.7813535143177992\n",
      "Model-2 features used: 43\n"
     ]
    }
   ],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "model_1 = Lasso()\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "model1_train_score = model_1.score(X_train, y_train)\n",
    "model1_test_score = model_1.score(X_test, y_test)\n",
    "model1f_used = np.sum(model_1.coef_ != 0)\n",
    "\n",
    "print(\"Model-1 train Score: {}\\nModel-1 test Score: {}\\nModel-1 features used: {}\".format(model1_train_score, model1_test_score, model1f_used))\n",
    "\n",
    "\n",
    "model_2 = Lasso(alpha=0.005, max_iter=100000)\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "model2_test_score = model_2.score(X_test, y_test)\n",
    "model2_train_score = model_2.score(X_train, y_train)\n",
    "model2_f_used = np.sum(model_2.coef_ != 0 )\n",
    "\n",
    "print(\"\\nModel-2 train Score: {}\\nModel-2 test Score: {}\\nModel-2 features used: {}\".format(model2_train_score, model2_test_score, model2_f_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
